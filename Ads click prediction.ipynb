{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyCqW9kX71RCMMsjvI9NRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uday1277/AIChatBot/blob/main/Ads%20click%20prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU0Yf2OXQazI",
        "outputId": "5b6a6993-8922-4637-cee5-3f6127982bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['Daily Time Spent on Site', 'Age', 'Area Income',\n",
            "       'Daily Internet Usage', 'Ad Topic Line', 'City', 'Male', 'Country',\n",
            "       'Timestamp', 'Clicked on Ad'],\n",
            "      dtype='object')\n",
            "First Few Rows:\n",
            "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
            "0                     68.95   35     61833.90                256.09   \n",
            "1                     80.23   31     68441.85                193.77   \n",
            "2                     69.47   26     59785.94                236.50   \n",
            "3                     74.15   29     54806.18                245.89   \n",
            "4                     68.37   35     73889.99                225.58   \n",
            "\n",
            "                           Ad Topic Line            City  Male     Country  \\\n",
            "0     Cloned 5thgeneration orchestration     Wrightburgh   0.0     Tunisia   \n",
            "1     Monitored national standardization       West Jodi   1.0       Nauru   \n",
            "2       Organic bottom-line service-desk        Davidton   0.0  San Marino   \n",
            "3  Triple-buffered reciprocal time-frame  West Terrifurt   1.0       Italy   \n",
            "4          Robust logistical utilization    South Manuel   0.0     Iceland   \n",
            "\n",
            "         Timestamp  Clicked on Ad  \n",
            "0   3/27/2016 0:53              0  \n",
            "1    4/4/2016 1:39              0  \n",
            "2  3/13/2016 20:35              0  \n",
            "3   1/10/2016 2:31              0  \n",
            "4    6/3/2016 3:36              0  \n",
            "XGBoost Accuracy: 0.4450\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
        "data = pd.read_csv('/content/Ad Click Data.csv')\n",
        "\n",
        "# Print column names to identify the correct target variable column\n",
        "print(\"Column Names:\", data.columns)\n",
        "\n",
        "# Print the first few rows of the dataset to verify its structure\n",
        "print(\"First Few Rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Assume your dataset has features 'X' and target variable 'y'\n",
        "# Replace 'actual_target_column_name' with the correct target variable column name\n",
        "# Make sure it's case-sensitive and matches the actual column name in your dataset\n",
        "target_column_name = 'Clicked on Ad'  # Replace with your actual target variable name\n",
        "try:\n",
        "    X = data.drop(target_column_name, axis=1)\n",
        "    y = data[target_column_name]\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"The target variable column '{target_column_name}' is not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['Ad Topic Line', 'City', 'Country', 'Timestamp']\n",
        "\n",
        "# Create a transformer for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with preprocessor and XGBoost model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the XGBoost model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for XGBoost\n",
        "xgb_predictions = model.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
        "data = pd.read_csv('/content/Ad Click Data.csv')\n",
        "\n",
        "# Print column names to identify the correct target variable column\n",
        "print(\"Column Names:\", data.columns)\n",
        "\n",
        "# Print the first few rows of the dataset to verify its structure\n",
        "print(\"First Few Rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Assume your dataset has features 'X' and target variable 'y'\n",
        "# Replace 'actual_target_column_name' with the correct target variable column name\n",
        "# Make sure it's case-sensitive and matches the actual column name in your dataset\n",
        "target_column_name = 'Clicked on Ad'  # Replace with your actual target variable name\n",
        "try:\n",
        "    X = data.drop(target_column_name, axis=1)\n",
        "    y = data[target_column_name]\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"The target variable column '{target_column_name}' is not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['Ad Topic Line', 'City', 'Country', 'Timestamp']\n",
        "\n",
        "# Create a transformer for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with preprocessor and Logistic Regression model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for Logistic Regression\n",
        "lr_predictions = model.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNgbapPqR9_Y",
        "outputId": "b6a0bc12-6b32-4e7e-e254-28c6081b5974"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['Daily Time Spent on Site', 'Age', 'Area Income',\n",
            "       'Daily Internet Usage', 'Ad Topic Line', 'City', 'Male', 'Country',\n",
            "       'Timestamp', 'Clicked on Ad'],\n",
            "      dtype='object')\n",
            "First Few Rows:\n",
            "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
            "0                     68.95   35     61833.90                256.09   \n",
            "1                     80.23   31     68441.85                193.77   \n",
            "2                     69.47   26     59785.94                236.50   \n",
            "3                     74.15   29     54806.18                245.89   \n",
            "4                     68.37   35     73889.99                225.58   \n",
            "\n",
            "                           Ad Topic Line            City  Male     Country  \\\n",
            "0     Cloned 5thgeneration orchestration     Wrightburgh   0.0     Tunisia   \n",
            "1     Monitored national standardization       West Jodi   1.0       Nauru   \n",
            "2       Organic bottom-line service-desk        Davidton   0.0  San Marino   \n",
            "3  Triple-buffered reciprocal time-frame  West Terrifurt   1.0       Italy   \n",
            "4          Robust logistical utilization    South Manuel   0.0     Iceland   \n",
            "\n",
            "         Timestamp  Clicked on Ad  \n",
            "0   3/27/2016 0:53              0  \n",
            "1    4/4/2016 1:39              0  \n",
            "2  3/13/2016 20:35              0  \n",
            "3   1/10/2016 2:31              0  \n",
            "4    6/3/2016 3:36              0  \n",
            "Logistic Regression Accuracy: 0.4550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
        "data = pd.read_csv('/content/Ad Click Data.csv')\n",
        "\n",
        "# Print column names to identify the correct target variable column\n",
        "print(\"Column Names:\", data.columns)\n",
        "\n",
        "# Print the first few rows of the dataset to verify its structure\n",
        "print(\"First Few Rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Assume your dataset has features 'X' and target variable 'y'\n",
        "# Replace 'actual_target_column_name' with the correct target variable column name\n",
        "# Make sure it's case-sensitive and matches the actual column name in your dataset\n",
        "target_column_name = 'Clicked on Ad'  # Replace with your actual target variable name\n",
        "try:\n",
        "    X = data.drop(target_column_name, axis=1)\n",
        "    y = data[target_column_name]\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"The target variable column '{target_column_name}' is not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['Ad Topic Line', 'City', 'Country', 'Timestamp']\n",
        "\n",
        "# Create a transformer for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with preprocessor and Random Forest model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for Random Forest\n",
        "rf_predictions = model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQHfldOZUe_0",
        "outputId": "7d573499-1e43-4e5a-e774-83d624051344"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['Daily Time Spent on Site', 'Age', 'Area Income',\n",
            "       'Daily Internet Usage', 'Ad Topic Line', 'City', 'Male', 'Country',\n",
            "       'Timestamp', 'Clicked on Ad'],\n",
            "      dtype='object')\n",
            "First Few Rows:\n",
            "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
            "0                     68.95   35     61833.90                256.09   \n",
            "1                     80.23   31     68441.85                193.77   \n",
            "2                     69.47   26     59785.94                236.50   \n",
            "3                     74.15   29     54806.18                245.89   \n",
            "4                     68.37   35     73889.99                225.58   \n",
            "\n",
            "                           Ad Topic Line            City  Male     Country  \\\n",
            "0     Cloned 5thgeneration orchestration     Wrightburgh   0.0     Tunisia   \n",
            "1     Monitored national standardization       West Jodi   1.0       Nauru   \n",
            "2       Organic bottom-line service-desk        Davidton   0.0  San Marino   \n",
            "3  Triple-buffered reciprocal time-frame  West Terrifurt   1.0       Italy   \n",
            "4          Robust logistical utilization    South Manuel   0.0     Iceland   \n",
            "\n",
            "         Timestamp  Clicked on Ad  \n",
            "0   3/27/2016 0:53              0  \n",
            "1    4/4/2016 1:39              0  \n",
            "2  3/13/2016 20:35              0  \n",
            "3   1/10/2016 2:31              0  \n",
            "4    6/3/2016 3:36              0  \n",
            "Random Forest Accuracy: 0.4600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
        "data = pd.read_csv('/content/Ad Click Data.csv')\n",
        "\n",
        "# Print column names to identify the correct target variable column\n",
        "print(\"Column Names:\", data.columns)\n",
        "\n",
        "# Print the first few rows of the dataset to verify its structure\n",
        "print(\"First Few Rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Assume your dataset has features 'X' and target variable 'y'\n",
        "# Replace 'actual_target_column_name' with the correct target variable column name\n",
        "# Make sure it's case-sensitive and matches the actual column name in your dataset\n",
        "target_column_name = 'Clicked on Ad'  # Replace with your actual target variable name\n",
        "try:\n",
        "    X = data.drop(target_column_name, axis=1)\n",
        "    y = data[target_column_name]\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"The target variable column '{target_column_name}' is not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['Ad Topic Line', 'City', 'Country', 'Timestamp']\n",
        "\n",
        "# Create a transformer for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with preprocessor and SVM model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the SVM model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for SVM\n",
        "svm_predictions = model.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIoI4QgfVHRD",
        "outputId": "7fcae8a3-8902-4eb7-cf35-a004ab111f9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['Daily Time Spent on Site', 'Age', 'Area Income',\n",
            "       'Daily Internet Usage', 'Ad Topic Line', 'City', 'Male', 'Country',\n",
            "       'Timestamp', 'Clicked on Ad'],\n",
            "      dtype='object')\n",
            "First Few Rows:\n",
            "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
            "0                     68.95   35     61833.90                256.09   \n",
            "1                     80.23   31     68441.85                193.77   \n",
            "2                     69.47   26     59785.94                236.50   \n",
            "3                     74.15   29     54806.18                245.89   \n",
            "4                     68.37   35     73889.99                225.58   \n",
            "\n",
            "                           Ad Topic Line            City  Male     Country  \\\n",
            "0     Cloned 5thgeneration orchestration     Wrightburgh   0.0     Tunisia   \n",
            "1     Monitored national standardization       West Jodi   1.0       Nauru   \n",
            "2       Organic bottom-line service-desk        Davidton   0.0  San Marino   \n",
            "3  Triple-buffered reciprocal time-frame  West Terrifurt   1.0       Italy   \n",
            "4          Robust logistical utilization    South Manuel   0.0     Iceland   \n",
            "\n",
            "         Timestamp  Clicked on Ad  \n",
            "0   3/27/2016 0:53              0  \n",
            "1    4/4/2016 1:39              0  \n",
            "2  3/13/2016 20:35              0  \n",
            "3   1/10/2016 2:31              0  \n",
            "4    6/3/2016 3:36              0  \n",
            "SVM Accuracy: 0.4550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
        "data = pd.read_csv('/content/Ad Click Data.csv')\n",
        "\n",
        "# Print column names to identify the correct target variable column\n",
        "print(\"Column Names:\", data.columns)\n",
        "\n",
        "# Print the first few rows of the dataset to verify its structure\n",
        "print(\"First Few Rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Assume your dataset has features 'X' and target variable 'y'\n",
        "# Replace 'actual_target_column_name' with the correct target variable column name\n",
        "# Make sure it's case-sensitive and matches the actual column name in your dataset\n",
        "target_column_name = 'Clicked on Ad'  # Replace with your actual target variable name\n",
        "try:\n",
        "    X = data.drop(target_column_name, axis=1)\n",
        "    y = data[target_column_name]\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"The target variable column '{target_column_name}' is not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['Ad Topic Line', 'City', 'Country', 'Timestamp']\n",
        "\n",
        "# Create a transformer for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline with preprocessor and KNN model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the KNN model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy for KNN\n",
        "knn_predictions = model.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLk_1mTPVi_v",
        "outputId": "3b656143-0f1c-4519-ebcd-e9a259ab83aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names: Index(['Daily Time Spent on Site', 'Age', 'Area Income',\n",
            "       'Daily Internet Usage', 'Ad Topic Line', 'City', 'Male', 'Country',\n",
            "       'Timestamp', 'Clicked on Ad'],\n",
            "      dtype='object')\n",
            "First Few Rows:\n",
            "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
            "0                     68.95   35     61833.90                256.09   \n",
            "1                     80.23   31     68441.85                193.77   \n",
            "2                     69.47   26     59785.94                236.50   \n",
            "3                     74.15   29     54806.18                245.89   \n",
            "4                     68.37   35     73889.99                225.58   \n",
            "\n",
            "                           Ad Topic Line            City  Male     Country  \\\n",
            "0     Cloned 5thgeneration orchestration     Wrightburgh   0.0     Tunisia   \n",
            "1     Monitored national standardization       West Jodi   1.0       Nauru   \n",
            "2       Organic bottom-line service-desk        Davidton   0.0  San Marino   \n",
            "3  Triple-buffered reciprocal time-frame  West Terrifurt   1.0       Italy   \n",
            "4          Robust logistical utilization    South Manuel   0.0     Iceland   \n",
            "\n",
            "         Timestamp  Clicked on Ad  \n",
            "0   3/27/2016 0:53              0  \n",
            "1    4/4/2016 1:39              0  \n",
            "2  3/13/2016 20:35              0  \n",
            "3   1/10/2016 2:31              0  \n",
            "4    6/3/2016 3:36              0  \n",
            "KNN Accuracy: 0.4550\n"
          ]
        }
      ]
    }
  ]
}